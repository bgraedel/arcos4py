{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARCOS Pipeline in python\n",
    "\n",
    "This notebook ilustrates a example workflow from images to ARCOS analysis and visualization in napari. It uses the python package stardist for segmenting nuclei, skimage for image processing and trackpy for tracking cells over time.\n",
    "Subsequently ARCOS is used to analyse and detect collective events.\n",
    "\n",
    "Example dataset is downloadable from: https://arcos.gitbook.io/home/example-use-cases/detecting-collective-signalling-events-in-epithelial-cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.13.0-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.13.0-cp310-cp310-win_amd64.whl (276.5 MB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached h5py-3.9.0-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached grpcio-1.56.2-cp310-cp310-win_amd64.whl (4.2 MB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.6)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: rsa, pyasn1-modules, opt-einsum, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.56.2 h5py-3.9.0 keras-2.13.1 opt-einsum-3.3.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-intel-2.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage\n",
    "import numpy\n",
    "\n",
    "from napari import Viewer\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "from skimage.measure import regionprops, regionprops_table\n",
    "from skimage.util import map_array\n",
    "\n",
    "import pandas as pd\n",
    "# import trackpy\n",
    "from arcos4py import ARCOS\n",
    "import errno\n",
    "\n",
    "TAB20 = [\n",
    "    \"#1f77b4\",\n",
    "    \"#aec7e8\",\n",
    "    \"#ff7f0e\",\n",
    "    \"#ffbb78\",\n",
    "    \"#2ca02c\",\n",
    "    \"#98df8a\",\n",
    "    \"#d62728\",\n",
    "    \"#ff9896\",\n",
    "    \"#9467bd\",\n",
    "    \"#c5b0d5\",\n",
    "    \"#8c564b\",\n",
    "    \"#c49c94\",\n",
    "    \"#e377c2\",\n",
    "    \"#f7b6d2\",\n",
    "    \"#7f7f7f\",\n",
    "    \"#c7c7c7\",\n",
    "    \"#bcbd22\",\n",
    "    \"#dbdb8d\",\n",
    "    \"#17becf\",\n",
    "    \"#9edae5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders(path: str, folder: list):\n",
    "    for i in folder:\n",
    "        folder_to_make = os.path.join(path, i)\n",
    "        try:\n",
    "            os.makedirs(folder_to_make)\n",
    "            print(f'folder \"{i}\" created')\n",
    "        except OSError as e:\n",
    "            print(f'folder \"{i}\" alrady exists')\n",
    "            if e.errno != errno.EEXIST:\n",
    "                raise\n",
    "def remap_segmentation(df: pd.DataFrame, segmentation: list, timepoint_column: str = 'timepoint', label_column: str = 'label', measure_column: str = 'ERK') -> list:\n",
    "    tracked_numpy = df[[timepoint_column, label_column, measure_column]].sort_values(timepoint_column).to_numpy()\n",
    "    grouped_numpy = numpy.split(tracked_numpy,numpy.unique(tracked_numpy[:,0], return_index = True)[1][1:])\n",
    "    ratio_remapped = []\n",
    "    for img, grp in zip(segmentation, grouped_numpy):\n",
    "        img_copy = map_array(img, grp[:,1], grp[:, 2])\n",
    "        ratio_remapped.append(img_copy)\n",
    "    return ratio_remapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define variables and create output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder \"data\" created\n",
      "folder \"stardist\" created\n"
     ]
    }
   ],
   "source": [
    "PATH = 'example_data' # where you data is located   \n",
    "FOLDER = 'mdck_ekar' # subfolder of PATH where images are stored\n",
    "OUT_DATA = 'data' # subfolder of PATH where csv is stored\n",
    "OUT_LABELS = 'stardist' # subfolder of PATH where stardist segmentation is stored\n",
    "FILENAME = 'C3-041_Ori.tif'\n",
    "full_path = os.path.join(PATH, FOLDER)\n",
    "orig_images_path = os.path.join(PATH, FOLDER)\n",
    "out_path_csv = os.path.join(PATH, OUT_DATA)\n",
    "create_folders(PATH, [OUT_DATA, OUT_LABELS]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load segmentation model and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\benig\\\\Documents\\\\python_dev\\\\arcos4py\\\\notebooks\\\\example_data\\\\mdck_ekar\\\\C3-041_Ori.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m StarDist2D\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m'\u001b[39m\u001b[39m2D_versatile_fluo\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# standard stardist model for 2d segmentation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m image_data \u001b[39m=\u001b[39m skimage\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mimread(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(orig_images_path, FILENAME))\n",
      "File \u001b[1;32mc:\\Users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages\\skimage\\io\\_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m         plugin \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtifffile\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[39mwith\u001b[39;00m file_or_url_context(fname) \u001b[39mas\u001b[39;00m fname:\n\u001b[1;32m---> 53\u001b[0m     img \u001b[39m=\u001b[39m call_plugin(\u001b[39m'\u001b[39m\u001b[39mimread\u001b[39m\u001b[39m'\u001b[39m, fname, plugin\u001b[39m=\u001b[39mplugin, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mplugin_args)\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(img, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages\\skimage\\io\\manage_plugins.py:205\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCould not find the plugin \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mplugin\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m for \u001b[39m\u001b[39m{\u001b[39;00mkind\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages\\skimage\\io\\_plugins\\tifffile_plugin.py:74\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mimg_num\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m     72\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mimg_num\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m tifffile_imread(fname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages\\tifffile\\tifffile.py:1094\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(files, selection, aszarr, key, series, level, squeeze, maxworkers, mode, name, offset, size, pattern, axesorder, categories, imread, sort, container, chunkshape, dtype, axestiled, ioworkers, chunkmode, fillvalue, zattrs, multiscales, omexml, out, out_inplace, _multifile, _useframes, **kwargs)\u001b[0m\n\u001b[0;32m   1089\u001b[0m     files \u001b[39m=\u001b[39m files[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(files, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m   1092\u001b[0m     files, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mSequence\n\u001b[0;32m   1093\u001b[0m ):\n\u001b[1;32m-> 1094\u001b[0m     \u001b[39mwith\u001b[39;00m TiffFile(\n\u001b[0;32m   1095\u001b[0m         files,\n\u001b[0;32m   1096\u001b[0m         mode\u001b[39m=\u001b[39mmode,\n\u001b[0;32m   1097\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   1098\u001b[0m         offset\u001b[39m=\u001b[39moffset,\n\u001b[0;32m   1099\u001b[0m         size\u001b[39m=\u001b[39msize,\n\u001b[0;32m   1100\u001b[0m         omexml\u001b[39m=\u001b[39momexml,\n\u001b[0;32m   1101\u001b[0m         _multifile\u001b[39m=\u001b[39m_multifile,\n\u001b[0;32m   1102\u001b[0m         _useframes\u001b[39m=\u001b[39m_useframes,\n\u001b[0;32m   1103\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mis_flags,\n\u001b[0;32m   1104\u001b[0m     ) \u001b[39mas\u001b[39;00m tif:\n\u001b[0;32m   1105\u001b[0m         \u001b[39mif\u001b[39;00m aszarr:\n\u001b[0;32m   1106\u001b[0m             \u001b[39massert\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages\\tifffile\\tifffile.py:4035\u001b[0m, in \u001b[0;36mTiffFile.__init__\u001b[1;34m(self, file, mode, name, offset, size, omexml, _multifile, _useframes, _parent, **is_flags)\u001b[0m\n\u001b[0;32m   4032\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr+b\u001b[39m\u001b[39m'\u001b[39m}:\n\u001b[0;32m   4033\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39minvalid mode \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 4035\u001b[0m fh \u001b[39m=\u001b[39m FileHandle(file, mode\u001b[39m=\u001b[39;49mmode, name\u001b[39m=\u001b[39;49mname, offset\u001b[39m=\u001b[39;49moffset, size\u001b[39m=\u001b[39;49msize)\n\u001b[0;32m   4036\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m fh\n\u001b[0;32m   4037\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multifile \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m _multifile \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mbool\u001b[39m(_multifile)\n",
      "File \u001b[1;32mc:\\Users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages\\tifffile\\tifffile.py:14020\u001b[0m, in \u001b[0;36mFileHandle.__init__\u001b[1;34m(self, file, mode, name, offset, size)\u001b[0m\n\u001b[0;32m  14018\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m  14019\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock \u001b[39m=\u001b[39m NullContext()\n\u001b[1;32m> 14020\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopen()\n\u001b[0;32m  14021\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benig\\miniconda3\\envs\\arcos4py_dev\\lib\\site-packages\\tifffile\\tifffile.py:14035\u001b[0m, in \u001b[0;36mFileHandle.open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  14033\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mrealpath(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file)\n\u001b[0;32m  14034\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_file)\n\u001b[1;32m> 14035\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fh \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m  14036\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_file, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mode, encoding\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m  14037\u001b[0m )  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m  14038\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m  14039\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\benig\\\\Documents\\\\python_dev\\\\arcos4py\\\\notebooks\\\\example_data\\\\mdck_ekar\\\\C3-041_Ori.tif'"
     ]
    }
   ],
   "source": [
    "model = StarDist2D.from_pretrained('2D_versatile_fluo') # standard stardist model for 2d segmentation\n",
    "image_data = skimage.io.imread(os.path.join(orig_images_path, FILENAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply segmentation and extract data from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path_stardist = os.path.join(PATH, OUT_LABELS,  'stardist.tif')\n",
    "segmentation = []\n",
    "df = []\n",
    "\n",
    "for t, tp_data in enumerate(image_data):\n",
    "    print(f'analysing timepoint {t}')\n",
    "    labels, _ = model.predict_instances(normalize(tp_data))\n",
    "    labels = skimage.segmentation.clear_border(labels)\n",
    "    dic = regionprops_table(labels, tp_data, properties=['label', 'centroid', 'intensity_mean', 'area'])\n",
    "    dic['timepoint'] = numpy.repeat(t, len(dic['label']))\n",
    "    df.append(pd.DataFrame(dic))\n",
    "    skimage.segmentation.clear_border(labels)\n",
    "    segmentation.append(labels)\n",
    "\n",
    "# optionally save segmentation\n",
    "skimage.io.imsave(out_path_stardist, numpy.stack(segmentation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track nuclei and export data as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat(df)\n",
    "df_full = df_full.rename(columns={\"centroid-1\": \"x\", \"centroid-0\": \"y\", 'intensity_mean': 'ERK'})\n",
    "df_full = df_full.sort_values(['timepoint'])\n",
    "df_tracked = trackpy.link_df(df_full, search_range = 10, memory = 2, t_column = 'timepoint')\n",
    "df_tracked = df_tracked.reset_index(drop=True).rename(columns={'particle': \"track_id\"})\n",
    "df_tracked.to_csv(out_path_csv+'\\\\tracked_data_fret.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Collective events with ARCOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ARCOS(df_tracked, [\"x\", \"y\"], 'timepoint','track_id', 'ERK')\n",
    "ts.interpolate_measurements()\n",
    "ts.bin_measurements(biasMet='none', binThr=0.28)\n",
    "df_arcos = ts.trackCollev(eps=40, minClsz=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Collective events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcos4py.tools import filterCollev\n",
    "\n",
    "filterer = filterCollev(df_arcos, 'timepoint', 'clTrackID', 'track_id')\n",
    "ts_filtered = filterer.filter(25, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Noodleplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcos4py.plotting import NoodlePlot\n",
    "\n",
    "NoodlePlot(ts_filtered, 'clTrackID', 'track_id', 'timepoint', 'x', 'y').plot('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data = df_tracked[['track_id', 'timepoint', 'y', 'x']].to_numpy()\n",
    "colors = numpy.take(numpy.array(TAB20), ts_filtered['clTrackID'].unique(), mode=\"wrap\")\n",
    "df_w_colors = pd.merge(ts_filtered, pd.DataFrame(data={'colors': colors, 'clTrackID': ts_filtered['clTrackID'].unique()}))\n",
    "points_data = df_w_colors[['timepoint', 'y', 'x']].to_numpy()\n",
    "colors_data = df_w_colors['colors'].to_numpy('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remap measured Ratio to segmentation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_remapped = numpy.stack(remap_segmentation(df_tracked, segmentation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add various layers to napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = Viewer()\n",
    "viewer.add_image(image_data, name='ERK Ratio image', colormap='inferno')\n",
    "viewer.add_image(ratio_remapped, colormap='viridis')\n",
    "viewer.add_labels(numpy.stack(segmentation), name='segmentation', visible=False)\n",
    "viewer.add_tracks(np_data, name='cell tracks')\n",
    "viewer.add_points(points_data, face_color=colors_data, name='collective events')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('arcos_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d7bacd3caf967cbc2ccebc22e1bb6cb8bcd40f665f711ff41f787508f4d17a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
